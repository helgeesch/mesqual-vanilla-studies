{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title_cell",
   "metadata": {},
   "source": [
    "# MESQUAL 202: KPI Collections and Pretty Tables\n",
    "\n",
    "This notebook demonstrates how to extract, organize, and present KPI data in well-formatted tables with automatic unit normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro_cell",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Building on the KPI framework fundamentals from notebook 201, this notebook focuses on practical data extraction and presentation:\n",
    "\n",
    "1. **DataFrame Export**: Converting KPI collections to pandas DataFrames\n",
    "2. **Unit Normalization**: Automatic unit selection for readable tables\n",
    "3. **Comparison KPIs**: Creating and analyzing scenario differences\n",
    "4. **Advanced Filtering**: Model property-based filtering\n",
    "5. **Pretty Tables**: Publication-ready table formatting\n",
    "6. **MultiIndex Support**: Hierarchical table organization\n",
    "\n",
    "These techniques enable rapid creation of analysis-ready tables from complex multi-scenario KPI collections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_cell",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we need to set up the environment. If you are on Colab, the first cell will clone and install all dependencies. You will have to restart the session afterwards and continue with cell 2. If you are in a local environment, make sure that you have followed the Getting started steps in the README, so that mesqual and all requirements are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"COLAB_RELEASE_TAG\" in os.environ:\n",
    "    import importlib.util\n",
    "\n",
    "    def is_module_available(module_name):\n",
    "        return importlib.util.find_spec(module_name) is not None\n",
    "\n",
    "    if os.path.exists(\"mesqual-vanilla-studies\") and is_module_available(\"mesqual\"):\n",
    "        print(\"âœ… Environment already set up. Skipping installation.\")\n",
    "    else:\n",
    "        print(\"ðŸ”§ Setting up Colab environment...\")\n",
    "        !git clone --recursive https://github.com/helgeesch/mesqual-vanilla-studies.git\n",
    "        %cd mesqual-vanilla-studies/\n",
    "\n",
    "        !pip install git+https://github.com/helgeesch/mesqual -U\n",
    "        !pip install git+https://github.com/helgeesch/mesqual-pypsa -U\n",
    "        !pip install git+https://github.com/helgeesch/captain-arro -U\n",
    "        !pip install -r requirements.txt\n",
    "\n",
    "        print('âœ… Setup complete. ðŸ” Restart the session, then skip this cell and continue with the next one.')\n",
    "else:\n",
    "    print(\"ðŸ–¥ï¸ Running locally. No setup needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"COLAB_RELEASE_TAG\" in os.environ:\n",
    "    import sys\n",
    "    sys.path.append('/content/mesqual-vanilla-studies')\n",
    "    os.chdir('/content/mesqual-vanilla-studies')\n",
    "else:\n",
    "    def setup_notebook_env():\n",
    "        \"\"\"Set working directory to repo root and ensure it's in sys.path.\"\"\"\n",
    "        import os\n",
    "        import sys\n",
    "        from pathlib import Path\n",
    "\n",
    "        def find_repo_root(start_path: Path) -> Path:\n",
    "            current = start_path.resolve()\n",
    "            while current != current.parent:\n",
    "                if (current / 'vanilla').exists():\n",
    "                    return current\n",
    "                current = current.parent\n",
    "            raise FileNotFoundError(f\"Repository root not found from: {start_path}\")\n",
    "\n",
    "        repo_root = find_repo_root(Path.cwd())\n",
    "        os.chdir(repo_root)\n",
    "        if str(repo_root) not in sys.path:\n",
    "            sys.path.insert(0, str(repo_root))\n",
    "\n",
    "    setup_notebook_env()\n",
    "\n",
    "try:\n",
    "    from mesqual import StudyManager\n",
    "except ImportError:\n",
    "    raise ImportError(\"âŒ 'mesqual' not found. If you're running locally, make sure you've installed all dependencies as described in the README.\")\n",
    "\n",
    "if not os.path.isdir(\"studies\"):\n",
    "    raise RuntimeError(f\"âŒ 'studies' folder not found. Make sure your working directory is set to the mesqual-vanilla-studies root. Current working directory: {os.getcwd()}\")\n",
    "\n",
    "print(\"âœ… Environment ready. Let's go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mesqual.kpis import FlagAggKPIBuilder, ComparisonKPIBuilder, Aggregations, ValueComparisons\n",
    "from mesqual.units import Units\n",
    "from vanilla.notebook_config import configure_clean_output_for_jupyter_notebook\n",
    "\n",
    "configure_clean_output_for_jupyter_notebook()\n",
    "\n",
    "# Pandas display options for better tables\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_study_header",
   "metadata": {},
   "source": [
    "## Load Study and Generate KPIs\n",
    "\n",
    "Let's load our study and create a comprehensive set of KPIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_study",
   "metadata": {},
   "outputs": [],
   "source": [
    "from studies.study_01_intro_to_mesqual.scripts.setup_study_manager import get_scigrid_de_study_manager\n",
    "\n",
    "study = get_scigrid_de_study_manager()\n",
    "\n",
    "# Clear any existing KPIs\n",
    "study.scen.clear_kpi_collection_for_all_child_datasets()\n",
    "study.comp.clear_kpi_collection_for_all_child_datasets()\n",
    "\n",
    "print(\"âœ… Study loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_kpis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate price KPIs for all scenarios\n",
    "price_def = (\n",
    "    FlagAggKPIBuilder()\n",
    "    .for_flag('control_areas_t.vol_weighted_marginal_price')\n",
    "    .with_aggregation(Aggregations.Mean)\n",
    "    .for_all_objects()\n",
    "    .build()\n",
    ")\n",
    "\n",
    "for dataset in study.scen.datasets:\n",
    "    kpis = price_def.generate_kpis(dataset)\n",
    "    dataset.kpi_collection.extend(kpis)\n",
    "    \n",
    "print(f\"âœ… Generated price KPIs for {len(study.scen.datasets)} scenarios\")\n",
    "print(f\"   Total KPIs: {study.scen.get_merged_kpi_collection().size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_header",
   "metadata": {},
   "source": [
    "## Part 1: Basic DataFrame Export\n",
    "\n",
    "The simplest way to export KPIs is to convert them to a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic_export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get KPI collection and export to DataFrame\n",
    "kpi_collection = study.scen.get_merged_kpi_collection()\n",
    "\n",
    "df = kpi_collection.to_dataframe()\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unit_handling_header",
   "metadata": {},
   "source": [
    "## Part 2: Unit Handling Strategies\n",
    "\n",
    "The KPI collection supports multiple unit handling strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original_units_header",
   "metadata": {},
   "source": [
    "### Strategy 1: Original Units (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original_units",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = kpi_collection.to_dataframe(unit_handling='original')\n",
    "print(\"Sample values with original units:\")\n",
    "print(df_original[['object_name', 'dataset_name', 'value', 'unit']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auto_convert_header",
   "metadata": {},
   "source": [
    "### Strategy 2: Auto-Convert to Pretty Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auto_convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pretty = kpi_collection.to_dataframe(unit_handling='auto_convert')\n",
    "print(\"Sample values with auto-converted pretty units:\")\n",
    "print(df_pretty[['object_name', 'dataset_name', 'value', 'unit']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normalize_header",
   "metadata": {},
   "source": [
    "### Strategy 3: Normalize to Collection\n",
    "\n",
    "Find a single \"pretty\" unit that works well for the entire collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized = kpi_collection.to_dataframe(normalize_to_collection=True)\n",
    "print(\"All values normalized to common unit:\")\n",
    "print(df_normalized[['object_name', 'dataset_name', 'value', 'unit']].head())\n",
    "print(f\"\\nAll units: {df_normalized['unit'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "target_unit_header",
   "metadata": {},
   "source": [
    "### Strategy 4: Target Unit\n",
    "\n",
    "Convert all KPIs to a specific unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "target_unit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eur_mwh = kpi_collection.to_dataframe(\n",
    "    unit_handling='target',\n",
    "    target_unit=Units.EUR / Units.MWh\n",
    ")\n",
    "print(\"All values in EUR/MWh:\")\n",
    "print(df_eur_mwh[['object_name', 'dataset_name', 'value', 'unit']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_header",
   "metadata": {},
   "source": [
    "## Part 3: Creating Pretty Tables\n",
    "\n",
    "Let's create analysis-ready tables with proper organization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pivot_table_header",
   "metadata": {},
   "source": [
    "### Pivot Table: Scenarios Ã— Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pivot_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export with normalized units\n",
    "df = kpi_collection.to_dataframe(normalize_to_collection=True)\n",
    "\n",
    "# Create pivot table\n",
    "pivot = df.pivot(index='object_name', columns='dataset_name', values='value')\n",
    "\n",
    "# Get the common unit for display\n",
    "common_unit = df['unit'].iloc[0]\n",
    "\n",
    "print(f\"Average Market Prices [{common_unit}]\")\n",
    "print(\"=\" * 80)\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "styled_table_header",
   "metadata": {},
   "source": [
    "### Styled Table with Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "styled_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create styled pivot table\n",
    "styled = pivot.style\\\n",
    "    .format(\"{:.2f}\")\\\n",
    "    .background_gradient(cmap='RdYlGn_r', axis=None)\\\n",
    "    .set_caption(f\"Average Market Prices by Control Area and Scenario [{common_unit}]\")\n",
    "\n",
    "styled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_header",
   "metadata": {},
   "source": [
    "## Part 4: Comparison KPIs\n",
    "\n",
    "Create and analyze scenario comparison KPIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_comparisons",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comparison KPIs\n",
    "for comp_dataset in study.comp.datasets:\n",
    "    scenario_kpis = comp_dataset.variation_dataset.kpi_collection\n",
    "    reference_kpis = comp_dataset.reference_dataset.kpi_collection\n",
    "    \n",
    "    for ref_kpi in reference_kpis:\n",
    "        # Find matching scenario KPI\n",
    "        matching = scenario_kpis.filter(\n",
    "            flag=ref_kpi.attributes.flag,\n",
    "            object_name=ref_kpi.attributes.object_name,\n",
    "            aggregation=ref_kpi.attributes.aggregation\n",
    "        )\n",
    "        \n",
    "        if matching.size > 0:\n",
    "            scenario_kpi = matching[0]\n",
    "            \n",
    "            # Create comparison KPIs\n",
    "            comp_def = (\n",
    "                ComparisonKPIBuilder()\n",
    "                .compare(scenario_kpi)\n",
    "                .to(ref_kpi)\n",
    "                .using_comparisons([\n",
    "                    ValueComparisons.AbsoluteDifference,\n",
    "                    ValueComparisons.RelativeDifference\n",
    "                ])\n",
    "                .build()\n",
    "            )\n",
    "            comp_kpis = comp_def.generate_kpis(None)\n",
    "            comp_dataset.kpi_collection.extend(comp_kpis)\n",
    "\n",
    "print(f\"âœ… Generated comparison KPIs for {len(study.comp.datasets)} comparisons\")\n",
    "print(f\"   Total comparison KPIs: {study.comp.get_merged_kpi_collection().size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_table_header",
   "metadata": {},
   "source": [
    "### Comparison Table: Absolute Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute difference KPIs\n",
    "comp_kpis = study.comp.get_merged_kpi_collection()\n",
    "abs_diff_kpis = comp_kpis.filter(value_comparison=ValueComparisons.AbsoluteDifference)\n",
    "\n",
    "# Export and pivot\n",
    "df_comp = abs_diff_kpis.to_dataframe(normalize_to_collection=True)\n",
    "pivot_comp = df_comp.pivot(index='object_name', columns='dataset_name', values='value')\n",
    "\n",
    "comp_unit = df_comp['unit'].iloc[0]\n",
    "\n",
    "print(f\"Price Changes vs Base Scenario [{comp_unit}]\")\n",
    "print(\"=\" * 80)\n",
    "print(pivot_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative_diff_header",
   "metadata": {},
   "source": [
    "### Relative Differences (Percentage Changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative_diff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relative difference KPIs\n",
    "rel_diff_kpis = comp_kpis.filter(value_comparison=ValueComparisons.RelativeDifference)\n",
    "\n",
    "# Export and pivot\n",
    "df_rel = rel_diff_kpis.to_dataframe()\n",
    "pivot_rel = df_rel.pivot(index='object_name', columns='dataset_name', values='value')\n",
    "\n",
    "# Convert to percentage\n",
    "pivot_rel = pivot_rel * 100\n",
    "\n",
    "print(f\"Relative Price Changes vs Base Scenario [%]\")\n",
    "print(\"=\" * 80)\n",
    "print(pivot_rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_header",
   "metadata": {},
   "source": [
    "## Part 5: Advanced Filtering\n",
    "\n",
    "Use model properties to filter KPIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_filtering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get KPIs for TenneTDE control area only\n",
    "all_kpis = study.scen.get_merged_kpi_collection()\n",
    "\n",
    "tennet_kpis = all_kpis.filter_by_model_property(\n",
    "    'object_name',\n",
    "    value='TenneTDE'\n",
    ")\n",
    "\n",
    "print(f\"KPIs for TenneTDE: {tennet_kpis.size}\")\n",
    "\n",
    "# Create table for single control area across scenarios\n",
    "df_tennet = tennet_kpis.to_dataframe(normalize_to_collection=True)\n",
    "print(f\"\\nTenneTDE Average Prices [{df_tennet['unit'].iloc[0]}]:\")\n",
    "print(df_tennet[['dataset_name', 'value']].set_index('dataset_name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_header",
   "metadata": {},
   "source": [
    "## Part 6: Combined Analysis Tables\n",
    "\n",
    "Combine scenarios and comparisons in unified tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get both scenario and comparison KPIs\n",
    "scenario_kpis = study.scen.get_merged_kpi_collection()\n",
    "comparison_kpis = study.comp.get_merged_kpi_collection().filter(\n",
    "    value_comparison=ValueComparisons.AbsoluteDifference\n",
    ")\n",
    "\n",
    "# Export both\n",
    "df_scen = scenario_kpis.to_dataframe(normalize_to_collection=True)\n",
    "df_comp = comparison_kpis.to_dataframe(normalize_to_collection=True)\n",
    "\n",
    "# Add type indicator\n",
    "df_scen['type'] = 'scenario'\n",
    "df_comp['type'] = 'change'\n",
    "\n",
    "# Combine\n",
    "df_combined = pd.concat([df_scen, df_comp], ignore_index=True)\n",
    "\n",
    "# Pivot for comparison\n",
    "pivot_combined = df_combined.pivot(\n",
    "    index='object_name',\n",
    "    columns=['type', 'dataset_name'],\n",
    "    values='value'\n",
    ")\n",
    "\n",
    "# Sort columns for better readability\n",
    "pivot_combined = pivot_combined.sort_index(axis=1, level=[1, 0])\n",
    "\n",
    "print(\"Combined Scenario Values and Changes\")\n",
    "print(\"=\" * 120)\n",
    "print(pivot_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7_header",
   "metadata": {},
   "source": [
    "## Part 7: Summary Statistics Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary_stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scenario KPIs\n",
    "df = scenario_kpis.to_dataframe(normalize_to_collection=True)\n",
    "\n",
    "# Calculate summary statistics by scenario\n",
    "summary = df.groupby('dataset_name')['value'].agg([\n",
    "    ('min', 'min'),\n",
    "    ('mean', 'mean'),\n",
    "    ('max', 'max'),\n",
    "    ('std', 'std')\n",
    "])\n",
    "\n",
    "unit = df['unit'].iloc[0]\n",
    "\n",
    "print(f\"Summary Statistics by Scenario [{unit}]\")\n",
    "print(\"=\" * 80)\n",
    "print(summary)\n",
    "\n",
    "# Styled version\n",
    "summary.style\\\n",
    "    .format(\"{:.2f}\")\\\n",
    "    .background_gradient(cmap='YlOrRd', subset=['mean', 'max'])\\\n",
    "    .set_caption(f\"Market Price Statistics by Scenario [{unit}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export_header",
   "metadata": {},
   "source": [
    "## Part 8: Exporting Tables\n",
    "\n",
    "Export tables for reports and presentations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_tables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "output_dir = 'non_versioned/output/kpi_tables'\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Scenario values\n",
    "pivot.to_csv(f'{output_dir}/scenario_prices.csv')\n",
    "print(f\"âœ… Exported scenario prices to {output_dir}/scenario_prices.csv\")\n",
    "\n",
    "# Comparison values\n",
    "pivot_comp.to_csv(f'{output_dir}/price_changes.csv')\n",
    "print(f\"âœ… Exported price changes to {output_dir}/price_changes.csv\")\n",
    "\n",
    "# Summary statistics\n",
    "summary.to_csv(f'{output_dir}/summary_statistics.csv')\n",
    "print(f\"âœ… Exported summary statistics to {output_dir}/summary_statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_header",
   "metadata": {},
   "source": [
    "## Summary: KPI Collection and Table Capabilities\n",
    "\n",
    "### DataFrame Export Strategies:\n",
    "\n",
    "1. **Original Units** (`unit_handling='original'`)\n",
    "   - Keep units as computed\n",
    "   - Best for raw data export\n",
    "\n",
    "2. **Auto-Convert** (`unit_handling='auto_convert'`)\n",
    "   - Each KPI converted to its own pretty unit\n",
    "   - Good for mixed KPI types\n",
    "\n",
    "3. **Normalize to Collection** (`normalize_to_collection=True`)\n",
    "   - Single common unit for entire collection\n",
    "   - **Best for tables and comparisons**\n",
    "   - Uses median order of magnitude\n",
    "\n",
    "4. **Target Unit** (`unit_handling='target', target_unit=...`)\n",
    "   - Explicit unit specification\n",
    "   - Useful for standard reporting formats\n",
    "\n",
    "### Table Creation Patterns:\n",
    "\n",
    "- **Pivot Tables**: `.pivot(index='object_name', columns='dataset_name', values='value')`\n",
    "- **Summary Stats**: `.groupby('dataset_name')['value'].agg([...])`\n",
    "- **MultiIndex**: Hierarchical column organization\n",
    "- **Styling**: `.style.format().background_gradient()`\n",
    "\n",
    "### Comparison Workflows:\n",
    "\n",
    "1. Generate scenario KPIs\n",
    "2. Create comparison KPIs with `ComparisonKPIBuilder`\n",
    "3. Filter by `value_comparison` type\n",
    "4. Export to DataFrame with normalized units\n",
    "5. Pivot and format\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "âœ… Use `normalize_to_collection=True` for consistent tables\n",
    "âœ… Filter before export to reduce data size\n",
    "âœ… Add type indicators when combining different KPI types\n",
    "âœ… Use styling for visual emphasis\n",
    "âœ… Export to CSV for sharing and archival"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The MESQUAL KPI collection system provides:\n",
    "\n",
    "âœ… **Flexible Export** - Multiple unit handling strategies\n",
    "âœ… **Automatic Normalization** - Smart unit selection for readable tables\n",
    "âœ… **Rich Filtering** - By attributes and model properties\n",
    "âœ… **Easy Pivoting** - Transform to analysis-ready formats\n",
    "âœ… **Publication Quality** - Styled tables with proper formatting\n",
    "\n",
    "These capabilities enable rapid creation of professional analysis tables from complex multi-scenario energy system studies, with minimal code and maximum clarity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
